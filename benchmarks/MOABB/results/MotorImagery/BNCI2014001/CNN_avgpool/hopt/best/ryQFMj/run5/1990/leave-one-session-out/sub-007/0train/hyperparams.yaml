# Generated 2024-04-16 from:
# /mnt/c/Users/Audrey/Desktop/C432_Machine_Learning/benchmarks/benchmarks/MOABB/results/MotorImagery/BNCI2014001/CNN_avgpool/hopt/best_hparams.yaml
# yamllint disable
seed: 1990
__set_torchseed: !apply:torch.manual_seed [1990]

# DIRECTORIES
data_folder: eeg_data/
                           #'/path/to/dataset'. The dataset will be automatically downloaded in this folder
cached_data_folder: eeg_data//pkl
                                 #'path/to/pickled/dataset'
output_folder: results/MotorImagery/BNCI2014001/CNN_avgpool/hopt/best/ryQFMj/run5/1990
                            #'path/to/results'

# DATASET HPARS
# Defining the MOABB dataset.
dataset: !new:moabb.datasets.BNCI2014001
save_prepared_dataset: true # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards
data_iterator_name: leave-one-session-out
target_subject_idx: 6
target_session_idx: 0
events_to_load:      # all events will be loaded
original_sample_rate: 250 # Original sampling rate provided by dataset authors
sample_rate: 125 # Target sampling rate (Hz)
# band-pass filtering cut-off frequencies
fmin: 0.14
fmax: 45.0
n_classes: 4
# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class
# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long
# dataset interval starts from 2
# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)
tmin: 0.
tmax: 4.0
# number of steps used when selecting adjacent channels from a seed channel (default at Cz)
n_steps_channel_selection: 3
T: 500
C: 22
# We here specify how to perfom test:
# - If test_with: 'last' we perform test with the latest model.
# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)
# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.
# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.
test_with: last   # 'last' or 'best'
test_key: acc   # Possible opts: "loss", "f1", "auc", "acc"

# METRICS
f1: &id001 !name:sklearn.metrics.f1_score
  average: macro
acc: &id002 !name:sklearn.metrics.balanced_accuracy_score
cm: &id003 !name:sklearn.metrics.confusion_matrix
# TRAINING HPARS
metrics:
  f1: *id001
  acc: *id002
  cm: *id003
n_train_examples: 232  # it will be replaced in the train script
# checkpoints to average
avg_models: 4
number_of_epochs: 981
lr: 0.001
# Learning rate scheduling (cyclic learning rate is used here)
max_lr: 0.001     # Upper bound of the cycle (max value of the lr)
base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)
step_size_multiplier: 5 #from 2 to 8
step_size: &id004 !apply:round
- 18.125
lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler
  base_lr: 0.00000001
  max_lr: 0.001
  step_size: *id004
label_smoothing: 0.0
loss: !name:speechbrain.nnet.losses.nll_loss
  label_smoothing: 0.0
optimizer: !name:torch.optim.Adam
  lr: 0.001
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
                                                               # epoch counter
  limit: 981
batch_size_exponent: 6
batch_size: 64
valid_ratio: 0.2

# DATA AUGMENTATION
# cutcat (disabled when min_num_segments=max_num_segments=1)
max_num_segments: 4
cutcat: &id007 !new:speechbrain.augment.time_domain.CutCat
  min_num_segments: 2
  max_num_segments: 4
# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)
amp_delta: 0.004194
rand_amp: &id008 !new:speechbrain.augment.time_domain.RandAmp
  amp_low: 0.995806
  amp_high: 1.004194
# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)
shift_delta_: 25 # orion_step2: --shift_delta_~"uniform(0, 25, discrete=True)"
shift_delta: 0.25                       # 0.250 # 0.-0.25 with steps of 0.01
min_shift: &id005 !apply:math.floor
- -31.25
max_shift: &id006 !apply:math.floor
- 31.25
time_shift: &id009 !new:speechbrain.augment.freq_domain.RandomShift
  min_shift: *id005
  max_shift: *id006
  dim: 1
# injection of gaussian white noise
snr_white_low: 2.0
snr_white_delta: 17.0
snr_white_high: 19.0
add_noise_white: &id010 !new:speechbrain.augment.time_domain.AddNoise
  snr_low: 2.0
  snr_high: 19.0

repeat_augment: 1 # @orion_step1: --repeat_augment 0
augment: !new:speechbrain.augment.augmenter.Augmenter
  parallel_augment: true
  concat_original: true
  parallel_augment_fixed_bs: true
  repeat_augment: 1
  shuffle_augmentations: true
  min_augmentations: 4
  max_augmentations: 4
  augmentations: [*id007, *id008, *id009, *id010]

# DATA NORMALIZATION
dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)
normalize: !name:speechbrain.processing.signal_processing.mean_std_norm
  dims: 1

# MODEL
input_shape: &id011 [null, 500, 22, null]
cnn_temporal_kernels: 30
cnn_spatial_kernels: 30
cnn_temporal_kernelsize: 17
cnn_poolsize_: 8
cnn_poolstride_: 1
# pool size / stride from 4/125 ms to 40/125 ms = circa 30 ms
cnn_poolsize: 32                       # same resolution as for EEGNet research space
cnn_poolstride: 4                          # same resolution as for EEGNet research space
cnn_pool_type: max
dropout: 0.4932
dense_max_norm: 0.25  # kernel max-norm constraint of the dense layer
dense_layer_1_neuron: 18
dense_layer_2_neuron: 7

model: !new:models.CNN.CNN
  input_shape: *id011
  cnn_temporal_kernels: 30
  cnn_temporal_kernelsize: [17, 1]
  cnn_spatial_kernels: 30
  cnn_poolsize: [32, 1]
  cnn_poolstride: [4, 1]
  cnn_pool_type: max
  dropout: 0.4932
  dense_max_norm: 0.25
  dense_layer_1_neuron: 18
  dense_layer_2_neuron: 7
  dense_out_neuron: 4

